{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a61cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q \"chronos-forecasting>=2.0\" scikit-learn matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970fec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/TheDatumOrg/TSB-AD.git\n",
      "  Cloning https://github.com/TheDatumOrg/TSB-AD.git to /tmp/pip-req-build-svopiou5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TheDatumOrg/TSB-AD.git /tmp/pip-req-build-svopiou5\n",
      "  Resolved https://github.com/TheDatumOrg/TSB-AD.git to commit 5e1d132ec3d9099eeaf9407c601004a0d2ec2d37\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (4.67.1)\n",
      "Collecting torchinfo (from TSB_AD==1.5)\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (3.15.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (0.8.1)\n",
      "Collecting numpy<2.0,>=1.24.3 (from TSB_AD==1.5)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (3.10.0)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (2.2.2)\n",
      "Collecting arch>=5.3.1 (from TSB_AD==1.5)\n",
      "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting hurst>=0.0.5 (from TSB_AD==1.5)\n",
      "  Downloading hurst-0.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting tslearn>=0.6.3 (from TSB_AD==1.5)\n",
      "  Downloading tslearn-0.7.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cython>=3.0.10 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (3.0.12)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (1.6.1)\n",
      "Requirement already satisfied: stumpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (1.13.0)\n",
      "Requirement already satisfied: networkx>=3.1 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (3.6.1)\n",
      "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from TSB_AD==1.5) (2.9.0+cu126)\n",
      "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch>=5.3.1->TSB_AD==1.5) (1.16.3)\n",
      "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch>=5.3.1->TSB_AD==1.5) (0.14.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch>=5.3.1->TSB_AD==1.5) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->TSB_AD==1.5) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->TSB_AD==1.5) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->TSB_AD==1.5) (2025.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.2->TSB_AD==1.5) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.2->TSB_AD==1.5) (3.6.0)\n",
      "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from stumpy>=1.12.0->TSB_AD==1.5) (0.60.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->TSB_AD==1.5) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.38.0->TSB_AD==1.5) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.38.0->TSB_AD==1.5) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->stumpy>=1.12.0->TSB_AD==1.5) (0.43.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->TSB_AD==1.5) (1.17.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch>=5.3.1->TSB_AD==1.5) (1.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->TSB_AD==1.5) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->TSB_AD==1.5) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->TSB_AD==1.5) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->TSB_AD==1.5) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->TSB_AD==1.5) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.38.0->TSB_AD==1.5) (2026.1.4)\n",
      "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hurst-0.0.5-py3-none-any.whl (5.9 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tslearn-0.7.0-py3-none-any.whl (372 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.7/372.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Building wheels for collected packages: TSB_AD\n",
      "  Building wheel for TSB_AD (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for TSB_AD: filename=TSB_AD-1.5-py3-none-any.whl size=169821 sha256=386b16bff267019abab979251fe8f9be7d22f3536ee122725c6aa58507617292\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-959f01q_/wheels/d1/c3/6e/123bd46f3b1b40273d118f7844ea2f2ee55db5ce8aa2fa704b\n",
      "Successfully built TSB_AD\n",
      "Installing collected packages: torchinfo, numpy, hurst, tslearn, arch, TSB_AD\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed TSB_AD-1.5 arch-8.0.0 hurst-0.0.5 numpy-1.26.4 torchinfo-1.8.0 tslearn-0.7.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "2c98ac92e25947dbb49b3fe4e06b229a",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install git+https://github.com/TheDatumOrg/TSB-AD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b292664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-23 08:59:25--  https://www.thedatum.org/datasets/TSB-AD-U.zip\n",
      "Resolving www.thedatum.org (www.thedatum.org)... 69.163.141.146\n",
      "Connecting to www.thedatum.org (www.thedatum.org)|69.163.141.146|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 72900868 (70M) [application/zip]\n",
      "Saving to: ‘TSB-AD-U.zip’\n",
      "\n",
      "TSB-AD-U.zip        100%[===================>]  69.52M  19.5MB/s    in 4.7s    \n",
      "\n",
      "2026-01-23 08:59:30 (14.9 MB/s) - ‘TSB-AD-U.zip’ saved [72900868/72900868]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se non l'hai ancora fatto:\n",
    "!wget https://www.thedatum.org/datasets/TSB-AD-U.zip\n",
    "!unzip -q TSB-AD-U.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d058fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chronos import Chronos2Pipeline\n",
    "from TSB_AD.evaluation.metrics import get_metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from json import dump as json_dump, load as json_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d20a7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(model_name: str = \"autogluon/chronos-2-small\", device: str = \"cuda\"):\n",
    "    \"\"\"Load Chronos-2 pipeline\"\"\"    \n",
    "    return Chronos2Pipeline.from_pretrained(model_name, device_map=\"cuda\" if device and torch.cuda.is_available() else \"cpu\", torch_dtype=torch.float32)\n",
    "\n",
    "\n",
    "def get_timestamp(start_date: str = \"2026-01-01 00:00:00\", periods: int = 100, freq: str = 'min'):\n",
    "    \"\"\"Generate timestamps for time series\"\"\"\n",
    "    return pd.date_range(start=start_date, periods=periods, freq=freq)\n",
    "\n",
    "\n",
    "def prepare_data_for_chronos(dataset_path: str):\n",
    "    \"\"\"\n",
    "    Prepare data in Chronos-2 format (DataFrame with timestamp, item_id, target columns)\n",
    "    \n",
    "    Returns:\n",
    "        - time_series_df: Formatted DataFrame for Chronos\n",
    "        - ground_truth_labels: Anomaly labels\n",
    "        - actual_future_values: Values to compare against predictions\n",
    "    \"\"\"\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(dataset_path, header=0, index_col=None)\n",
    "    \n",
    "    # Remove label from data\n",
    "    df_clean = df.drop(columns=[df.columns[-1]]).copy()\n",
    "    \n",
    "    # Create Chronos-compatible DataFrame\n",
    "    df_chronos = pd.DataFrame()\n",
    "    df_chronos['timestamp'] = get_timestamp(periods=len(df_clean))\n",
    "    df_chronos['item_id'] = 0  # Single time series\n",
    "    df_chronos[df.columns[0]] = df_clean[df.columns[0]].values\n",
    "    \n",
    "    return df_chronos, df[df.columns[-1]].values, df.columns[0]\n",
    "\n",
    "\n",
    "def make_predictions_sliding_window(time_series_df: pd.DataFrame,pipeline: Chronos2Pipeline,target_col: str,context_length: int = 100,prediction_length: int = 1,step_size: int = 1,batch_size: int = 32,\n",
    "                                    quantile_levels: list[float] = [0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99]):\n",
    "    \"\"\"\n",
    "    Generate predictions using sliding window approach\n",
    "    \n",
    "    Args:\n",
    "        time_series_df: DataFrame with columns [timestamp, item_id, target]\n",
    "        pipeline: Chronos2Pipeline instance\n",
    "        target_col: Name of target column\n",
    "        context_length: Number of historical points for context\n",
    "        prediction_length: Number of steps to forecast\n",
    "        step_size: Stride of sliding window\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        predictions_df: DataFrame with predictions and quantiles\n",
    "        prediction_indices: Indices in original series corresponding to each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions_list, prediction_indices = [], []\n",
    "    \n",
    "    # Prepare context-future pairs\n",
    "    contexts, futures, indices = [], [], []\n",
    "    \n",
    "    #create sliding windows \n",
    "    idx = context_length\n",
    "    while idx + prediction_length <= len(time_series_df):\n",
    "        # Extract context\n",
    "        contexts.append(time_series_df.iloc[idx - context_length:idx].copy())\n",
    "        \n",
    "        # Extract future metadata (timestamp, item_id for next step)\n",
    "        futures.append(time_series_df[['timestamp', 'item_id']].iloc[idx:idx + prediction_length].copy())\n",
    "        \n",
    "        indices.append(idx)\n",
    "        idx += step_size\n",
    "    \n",
    "    print(f\"Total prediction windows: {len(contexts)}\")\n",
    "    \n",
    "    # Process in batches\n",
    "    for batch_start in range(0, len(contexts), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(contexts)) #l'ultimo batch potrebbe essere più piccolo\n",
    "        batch_contexts = contexts[batch_start:batch_end]\n",
    "        \n",
    "        try:\n",
    "            # Combine contexts with unique item_id\n",
    "            combined_contexts = []\n",
    "            for i, ctx in enumerate(batch_contexts):\n",
    "                ctx_copy = ctx.copy()\n",
    "                ctx_copy['item_id'] = i\n",
    "                combined_contexts.append(ctx_copy)\n",
    "            \n",
    "            # Combine futures with matching item_id\n",
    "            combined_futures = []\n",
    "            for i, fut in enumerate(futures[batch_start:batch_end]):\n",
    "                fut_copy = fut.copy()\n",
    "                fut_copy['item_id'] = i\n",
    "                combined_futures.append(fut_copy)\n",
    "            \n",
    "            # Make predictions\n",
    "            pred_df = pipeline.predict_df(\n",
    "                df=pd.concat(combined_contexts, ignore_index=True),\n",
    "                future_df=pd.concat(combined_futures, ignore_index=True),\n",
    "                target=target_col,\n",
    "                prediction_length=prediction_length,\n",
    "                quantile_levels=quantile_levels,  # Use multiple quantiles\n",
    "                cross_learning=False,\n",
    "                batch_size=len(batch_contexts),\n",
    "            )\n",
    "            \n",
    "            predictions_list.append(pred_df)\n",
    "            \n",
    "            # Map each prediction row to its corresponding timestep index\n",
    "            # When prediction_length > 1, each context window produces prediction_length predictions\n",
    "            for start_idx in indices[batch_start:batch_end]:\n",
    "                for pred_step in range(prediction_length):\n",
    "                    prediction_indices.append(start_idx + pred_step)\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting at index {batch_start}: {e}\")\n",
    "\n",
    "    if predictions_list:\n",
    "        return pd.concat(predictions_list, ignore_index=True), np.array(prediction_indices)\n",
    "    return pd.DataFrame(), np.array(prediction_indices)\n",
    "\n",
    "\n",
    "def detect_anomalies_reconstruction_error(predictions_df: pd.DataFrame,actual_values: np.ndarray, thresholds_percentile:list[list[float]] = \n",
    "                                            [[0.2, 0.8], [0.01, 0.99],[0.05, 0.95],[0.025, 0.975],[0.1, 0.9]]):\n",
    "    \"\"\"\n",
    "    Detect anomalies using reconstruction error (prediction error)\n",
    "    \n",
    "    Args:\n",
    "        predictions_df: DataFrame with '0.5' column (median predictions)\n",
    "        actual_values: Actual observed values\n",
    "        thresholds_percentile: List of [lower_percentile, upper_percentile] pairs for thresholding\n",
    "        \n",
    "    Returns:\n",
    "        anomaly_labels: Binary array (0=normal, 1=anomaly)\n",
    "        reconstruction_errors: Absolute errors\n",
    "        threshold: Used threshold\n",
    "    \"\"\"\n",
    "    return ([((actual_values < predictions_df[str(q_low)].to_numpy()) | (actual_values > predictions_df[str(q_high)].to_numpy())).astype(np.int8) \n",
    "            for q_low, q_high in thresholds_percentile], thresholds_percentile)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_dataset(dataset_path: str,pipeline: Chronos2Pipeline,context_length: int = 100,\n",
    "        thresholds_percentile: list[list[float]] = [[0.2, 0.8], [0.01, 0.99], [0.05, 0.95], [0.025, 0.975],[0.1, 0.9]],\n",
    "        step_size: int = 1,batch_size: int = 32, prediction_length: int = 1):\n",
    "    \"\"\"\n",
    "    Complete evaluation pipeline for a single dataset\n",
    "    \"\"\"\n",
    "    print(f\"Processing: {os.path.basename(dataset_path)}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    time_series_df, ground_truth_labels, target_col = prepare_data_for_chronos(dataset_path)\n",
    "    \n",
    "    print(f\"Ground truth anomaly rate: {np.mean(ground_truth_labels):.2%}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions_df, prediction_indices = make_predictions_sliding_window(\n",
    "        time_series_df=time_series_df,\n",
    "        pipeline=pipeline,\n",
    "        target_col=target_col,\n",
    "        context_length=context_length,\n",
    "        prediction_length=prediction_length,\n",
    "        step_size=step_size,\n",
    "        batch_size=batch_size,\n",
    "        quantile_levels=[t for v in thresholds_percentile for t in v] + [0.5] \n",
    "    )\n",
    "    \n",
    "    if not len(predictions_df):\n",
    "        print(\"No predictions generated!\")\n",
    "        return None\n",
    "    \n",
    "    # Detect anomalies using reconstruction error\n",
    "    predictedAnomalies, th  = detect_anomalies_reconstruction_error(\n",
    "        predictions_df=predictions_df,\n",
    "        actual_values=time_series_df[target_col].iloc[prediction_indices].values,\n",
    "        thresholds_percentile=thresholds_percentile\n",
    "    )\n",
    "\n",
    "    # Calculate metrics\n",
    "    return {\n",
    "        'file': os.path.basename(dataset_path),\n",
    "        \"thresholds\": th,\n",
    "        'metrics':[{\n",
    "            **get_metrics(predicted, ground_truth_labels[prediction_indices]),\n",
    "            'accuracy': float(accuracy_score(ground_truth_labels[prediction_indices], predicted)),\n",
    "            'precision': float(precision_score(ground_truth_labels[prediction_indices], predicted, zero_division=0)),\n",
    "            'recall': float(recall_score(ground_truth_labels[prediction_indices], predicted, zero_division=0)),\n",
    "            'f1_score': float(f1_score(ground_truth_labels[prediction_indices], predicted, zero_division=0)),\n",
    "            'confusion_matrix': confusion_matrix(ground_truth_labels[prediction_indices], predicted).tolist(),\n",
    "            'thresholds': t} for t, predicted in zip(th, predictedAnomalies)]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Skipping file: 001_NAB_id_1_Facility_tr_1007_1st_2014.csv\n",
      "Skipping file: 002_NAB_id_2_WebService_tr_1500_1st_4106.csv\n",
      "Skipping file: 003_NAB_id_3_WebService_tr_1362_1st_1462.csv\n",
      "Processing: 004_NAB_id_4_Facility_tr_1007_1st_1437.csv\n",
      "Ground truth anomaly rate: 9.97%\n",
      "Total prediction windows: 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 004_NAB_id_4_Facility_tr_1007_1st_1437.csv\n",
      "Processing: 005_NAB_id_5_Traffic_tr_594_1st_1645.csv\n",
      "Ground truth anomaly rate: 10.00%\n",
      "Total prediction windows: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 005_NAB_id_5_Traffic_tr_594_1st_1645.csv\n",
      "Processing: 006_NAB_id_6_Traffic_tr_2579_1st_5839.csv\n",
      "Ground truth anomaly rate: 9.98%\n",
      "Total prediction windows: 1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 006_NAB_id_6_Traffic_tr_2579_1st_5839.csv\n",
      "Processing: 007_NAB_id_7_Traffic_tr_624_1st_2087.csv\n",
      "Ground truth anomaly rate: 9.92%\n",
      "Total prediction windows: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 007_NAB_id_7_Traffic_tr_624_1st_2087.csv\n",
      "Processing: 008_NAB_id_8_Synthetic_tr_1007_1st_2734.csv\n",
      "Ground truth anomaly rate: 9.97%\n",
      "Total prediction windows: 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 008_NAB_id_8_Synthetic_tr_1007_1st_2734.csv\n",
      "Processing: 009_NAB_id_9_Traffic_tr_500_1st_438.csv\n",
      "Ground truth anomaly rate: 10.00%\n",
      "Total prediction windows: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 009_NAB_id_9_Traffic_tr_500_1st_438.csv\n",
      "Processing: 010_NAB_id_10_WebService_tr_500_1st_271.csv\n",
      "Ground truth anomaly rate: 14.80%\n",
      "Total prediction windows: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for 010_NAB_id_10_WebService_tr_500_1st_271.csv\n",
      "Processing: 011_NAB_id_11_Facility_tr_1007_1st_1526.csv\n",
      "Ground truth anomaly rate: 11.76%\n",
      "Total prediction windows: 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main execution\"\"\"\n",
    "\n",
    "# Configuration\n",
    "# data_path = \"./Nunzio/data/TSB-AD-U/\"\n",
    "data_path = \"TSB-AD-U\"\n",
    "out_initial_path = \"./results/univariate/\"\n",
    "\n",
    "os.makedirs(out_initial_path, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "context_length = 100\n",
    "thresholds_percentile = [[0.2, 0.8], [0.1, 0.9], [0.05, 0.95], [0.025, 0.975], [0.01, 0.99]]\n",
    "step_size = 10 \n",
    "batch_size = 32\n",
    "prediction_length = 10\n",
    "\n",
    "pipeline = get_pipeline(device='cuda')\n",
    "print(f\"Using device: {next(pipeline.model.parameters()).device}\")\n",
    "\n",
    "if os.path.exists(os.path.join(out_initial_path, \"results.json\")):\n",
    "    with open(os.path.join(out_initial_path, \"results.json\"), 'r', encoding='utf-8') as f:\n",
    "        existing_results = json_load(f)\n",
    "else:\n",
    "    existing_results = {}\n",
    "\n",
    "# Process datasets\n",
    "for filename in sorted(os.listdir(data_path)):\n",
    "    if not filename.endswith('.csv') or filename in existing_results:\n",
    "        print(f\"Skipping file: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    result = evaluate_dataset(\n",
    "        os.path.join(data_path, filename),\n",
    "        pipeline=pipeline,\n",
    "        context_length=context_length,\n",
    "        thresholds_percentile=thresholds_percentile,\n",
    "        step_size=step_size,\n",
    "        batch_size=batch_size,\n",
    "        prediction_length=prediction_length\n",
    "    )\n",
    "    \n",
    "    if result is not None:\n",
    "        with open(os.path.join(out_initial_path, \"results.json\"), 'w', encoding='utf-8') as f:\n",
    "            existing_results[filename] = {**result, 'context_length': context_length, 'prediction_length': prediction_length,\n",
    "                        'step_size': step_size, \"batch_size\": batch_size}\n",
    "            json_dump(existing_results, f, indent=4)\n",
    "            print(f\"Results saved for {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
