{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a857d0",
   "metadata": {},
   "source": [
    "# <b>ASYNCHRONOUS PUBLISH-SUBSCRIBE ANOMALY DETECTION WITH CHRONOS-2</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c75e2",
   "metadata": {},
   "source": [
    "Firstly, we need to import the necessary libraries and modules for our project. We will be using Chronos-2 for anomaly detection, along with other libraries for data handling and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from json import loads as json_loads\n",
    "from chronos import Chronos2Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myQueue():\n",
    "    def __init__(self, max_size:int):\n",
    "        self.data = []\n",
    "        self.anomaly = []\n",
    "        self.timestamp = []\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def push(self, data, anomaly, timestamp):\n",
    "        if len(self.data) >= self.max_size:\n",
    "            self.data.pop(0), \n",
    "            self.anomaly.pop(0)\n",
    "            self.timestamp.pop(0)\n",
    "        self.data.append(data)\n",
    "        self.anomaly.append(anomaly)\n",
    "        self.timestamp.append(timestamp)\n",
    "\n",
    "    def getData(self):\n",
    "        return list(self.data)\n",
    "    \n",
    "    def getAnomaly(self):\n",
    "        return list(self.anomaly)\n",
    "    \n",
    "    def getTimestamp(self):\n",
    "        return list(self.timestamp)\n",
    "    \n",
    "    def getAll(self):\n",
    "        return list(zip(self.timestamp, self.data, self.anomaly))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def isFull(self):\n",
    "        return len(self.data) >= self.max_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca76ec2",
   "metadata": {},
   "source": [
    "# Chronos-2 Model\n",
    "Next, we will initialize our Chronos-2 model for anomaly detection. We will load the pre-trained model and set it up for real-time inference on the incoming data from the MQTT client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pipeline = Chronos2Pipeline.from_pretrained(\"amazon/chronos-2\", device_map=device)\n",
    "print(\"Model loaded successfully on device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09e1a4",
   "metadata": {},
   "source": [
    "# Predicting functions\n",
    "We will define the necessary functions to process the incoming data and make predictions using the Chronos-2 model. This will include functions for data preprocessing, anomaly detection, and handling the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9260ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predictNextPoint(chronos:Chronos2Pipeline, context:myQueue)->np.ndarray:\n",
    "    \"\"\"Predict the next point in the time series given the context using the Chronos-2 model.\n",
    "    \n",
    "    Args:\n",
    "        chronos (Chronos2Pipeline): The Chronos-2 model pipeline for time series forecasting.\n",
    "        context (myQueue): A list of historical data points to be used as context for prediction.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The predicted next point in the time series.\n",
    "    \"\"\"\n",
    "    return chronos.predict(torch.tensor(context.getData()).T.unsqueeze(0), prediction_length=1, context_length=len(context), cross_learning=False)[0].squeeze(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAnomaly(prediction:np.ndarray, actual:np.ndarray, threshold:float=5.99)->bool:\n",
    "    \"\"\"Determine if the actual value is an anomaly based on the predicted distribution\n",
    "    and a quantile threshold.\n",
    "    \n",
    "    Args:\n",
    "        prediction (np.ndarray): The predicted value from the model.\n",
    "        actual (np.ndarray): The actual observed value.\n",
    "        threshold (float): The chi-squared threshold for anomaly detection (default is 5.99 for 95% confidence).\n",
    "        \n",
    "    Returns:\n",
    "        anomaly (int): 1 if anomaly, 0 if not, -1 if not enough data.\n",
    "    \"\"\"\n",
    "    # Stima spread usando IQR\n",
    "    spread = (prediction[:, 15] - prediction[:, 5]) / 1.35  # Approx standard deviation\n",
    "        \n",
    "    # Mahalanobis distance semplificato (assume indipendenza)\n",
    "    # Per correlazione vera, serve covarianza completa                \n",
    "    return int(np.sqrt(np.sum(((actual - prediction[:, 10]) / (spread + 1e-8)) ** 2)) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae35e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyInference(data:np.ndarray, context:myQueue, chronos:Chronos2Pipeline, threshold:float=5.99)->int:\n",
    "    \"\"\"Process incoming data, make predictions, and determine if the new data point is an anomaly.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): The new incoming data point to be evaluated.\n",
    "        context (myQueue): A queue containing historical data points for context.\n",
    "        chronos (Chronos2Pipeline): The Chronos-2 model pipeline for making predictions.\n",
    "        threshold (float): The chi-squared threshold for anomaly detection (default is 5.99 for 95% confidence).\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the new data point is an anomaly, 0 if it is not, -1 if there is not enough data.\n",
    "    \"\"\"\n",
    "    if not context.isFull():\n",
    "        return -1 # Not enough data to make a prediction yet\n",
    "\n",
    "    # Get the predicted next point from the model\n",
    "    prediction = predictNextPoint(chronos, context)\n",
    "    \n",
    "    # Determine if the actual value is an anomaly\n",
    "    return isAnomaly(prediction, data, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f45bde",
   "metadata": {},
   "source": [
    "# Message handling\n",
    "We will implement a message handling function that will be called whenever a new message is received from the MQTT broker. This function will handle the incoming stream of data to check its correctness and perform anomaly detection on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkCorrectness(msg:dict[str, int|float|list[dict[str, str|float]]])->tuple[bool, list[str]]:\n",
    "    \"\"\"Check if the message has the correct structure.\n",
    "    \n",
    "    Args:\n",
    "        msg (dict): The message to check.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing a boolean indicating if the message has the correct structure and a list of error messages.\n",
    "    \"\"\"\n",
    "    errorMsg:list[str] = []\n",
    "    \n",
    "    # Check keys\n",
    "    if set(msg.keys()) != {'mac_address', 'timestamp', 'data'}:\n",
    "        errorMsg.append(\"Message keys are not correct\")\n",
    "    \n",
    "    # Check types of principal keys\n",
    "    if 'mac_address' in msg and not isinstance(msg['mac_address'], str):\n",
    "        errorMsg.append(\"mac_address is not a string\")\n",
    "    if 'timestamp' in msg and not isinstance(msg['timestamp'], int):\n",
    "        errorMsg.append(\"timestamp is not an integer\")\n",
    "        \n",
    "    # Check data entries\n",
    "    if 'data' in msg and isinstance(msg['data'], dict) and set(msg['data'].keys()) == {'temperature', 'humidity'}:\n",
    "        if \"temperature\" not in msg['data'] or not isinstance(msg['data']['temperature'], (int, float)):\n",
    "                errorMsg.append(\"Data entry temperature is not a number\")\n",
    "        if 'humidity' not in msg['data'] or not isinstance(msg['data']['humidity'], (int, float)):\n",
    "                errorMsg.append(\"Data entry humidity is not a number\")\n",
    "    else:\n",
    "        errorMsg.append(\"Data is not a dictionary or does not have the correct keys\")\n",
    "    \n",
    "    return not len(errorMsg), errorMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected successfully to MQTT broker\")\n",
    "    else:\n",
    "        print(f\"Connection failed with code {rc}\")            \n",
    "    \n",
    "    # Subscribe to a topic when the client connects\n",
    "    client.subscribe('s344860')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0389e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message(client, userdata, msg):    \n",
    "    # Decode the message\n",
    "    message = json_loads(msg.payload.decode())\n",
    "    queue = userdata['context']\n",
    "    \n",
    "    is_correct, errors = checkCorrectness(message)\n",
    "\n",
    "    if not is_correct:\n",
    "        print(\"Received incorrect message. Errors:\", errors)\n",
    "        return\n",
    "        \n",
    "    values = np.array([message['data']['temperature'], message['data']['humidity']])\n",
    "    \n",
    "    score = anomalyInference(values, queue, userdata['pipeline'], userdata['threshold'])\n",
    "\n",
    "    queue.push(values, score, message['timestamp'])\n",
    "\n",
    "    timestamp = datetime.fromtimestamp(message['timestamp']/1_000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    match score:\n",
    "        case 1: print(f\"\\033[91m ANOMALY DETECTED: (Timestamp: {timestamp}, Temperature: {values[0]:.1f}°C, Humidity: {values[1]:.1f}%)\\033[0m\")\n",
    "        case 0: print(f\"\\033[92m NOT AN ANOMALY: (Timestamp: {timestamp}, Temperature: {values[0]:.1f}°C, Humidity: {values[1]:.1f}%)\\033[0m\")\n",
    "        case -1: print(f\"\\033[94m Not enough data, need {queue.max_size - len(queue)} more for context \\033[0m\")\n",
    "        case _: raise ValueError(f\"Unexpected score value: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a59d0",
   "metadata": {},
   "source": [
    "# Client\n",
    "We will be using the Paho MQTT client to connect to our MQTT broker and subscribe to the relevant topics for receiving data. The client will be set up to handle incoming messages and process them for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa480a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mqtt.Client()\n",
    "CONTEXT_LENGTH = 32\n",
    "# Threshold: chi-squared(2 dof, 95%) ≈ 5.99\n",
    "# Più conservativo: 7.81 (99%)\n",
    "# mediamente bilanciato: 5.99 (95%)\n",
    "# Più aggressivo: 4.61 (90%)\n",
    "THRESHOLD = 5.99\n",
    "\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a948788",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.connect('broker.emqx.io', 1883)\n",
    "\n",
    "# Set user data\n",
    "client.user_data_set({'pipeline': pipeline,'context':  myQueue(CONTEXT_LENGTH), 'threshold': THRESHOLD})\n",
    "\n",
    "\n",
    "client.loop_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
